<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小黑屋</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kodgv.xyz/"/>
  <updated>2019-04-08T16:14:04.808Z</updated>
  <id>http://kodgv.xyz/</id>
  
  <author>
    <name>KODGV</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>targetencoding</title>
    <link href="http://kodgv.xyz/2019/04/08/targetencoding/"/>
    <id>http://kodgv.xyz/2019/04/08/targetencoding/</id>
    <published>2019-04-08T14:57:06.000Z</published>
    <updated>2019-04-08T16:14:04.808Z</updated>
    
    <content type="html"><![CDATA[<p>​    当你在进行监督学习时，你经常要处理分类变量。也就是说，变量没有一个自然的数值表示。问题是大多数机器学习算法都要求输入数据是数值的。在某个时候，数据科学管道将需要将分类变量转换为数值变量。</p><a id="more"></a><p>来源：<a href="https://maxhalford.github.io/blog/target-encoding-done-the-right-way/" target="_blank" rel="noopener">https://maxhalford.github.io/blog/target-encoding-done-the-right-way/</a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    当你在进行监督学习时，你经常要处理分类变量。也就是说，变量没有一个自然的数值表示。问题是大多数机器学习算法都要求输入数据是数值的。在某个时候，数据科学管道将需要将分类变量转换为数值变量。</p><p>有很多方法可以做到这一点:</p><ul><li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" target="_blank" rel="noopener">Label encoding</a> 为每个类别选择数字</li><li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" target="_blank" rel="noopener">One-hot encoding</a>:为每个类别创建一个二进制列</li><li><a href="https://www.tensorflow.org/tutorials/representation/word2vec" target="_blank" rel="noopener">Vector representation</a> ：也就是word2vec，在这里您可以找到一个适合您的数据的低维子空间</li><li><a href="https://github.com/Microsoft/LightGBM/blob/master/docs/Advanced-Topics.rst#categorical-feature-support" target="_blank" rel="noopener">Optimal binning</a> ：在依赖于LightGBM或CatBoost等树学习器</li><li><a href="http://www.saedsayad.com/encoding.htm" target="_blank" rel="noopener">Target encoding</a>: 按类别平均目标值</li></ul><p>​    每种方法都有其优缺点，通常取决于您的数据和需求。如果一个变量有很多类别，那么一个[<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" target="_blank" rel="noopener">One-hot encoding</a>:方案将产生许多列，这可能导致内存问题。根据我的经验，依赖LightGBM/CatBoost是最好的分箱方法。<a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" target="_blank" rel="noopener">Label encoding</a>是没有用的，最好不要使用它。然而，如果你的分类变量恰好是有序的，那么你可以而且应该用递增的数字来表示它(例如，“cold”变成0，“mild”变成1，“hot”变成2)。word2vec和其他类似的方法很酷也很好，但是它们需要进行一些微调，而且并不总是奏效。</p><h2 id="target-encoding"><a href="#target-encoding" class="headerlink" title="target encoding"></a>target encoding</h2><pre><code>target encoding是很容易理解的一种思想，假设你有分类变量X和变量Y，然后对于X中每一个distinct的元素计算其对应Y值的平局之，然后用这个平均值替换 $ x_i $ .下面这个例子显而易见：</code></pre><table><thead><tr><th>x0</th><th>x1</th><th>y</th></tr></thead><tbody><tr><td>aa</td><td>cc</td><td>1</td></tr><tr><td>aa</td><td>cc</td><td>1</td></tr><tr><td>aa</td><td>cc</td><td>1</td></tr><tr><td>aa</td><td>cc</td><td>1</td></tr><tr><td>aa</td><td>cc</td><td>0</td></tr><tr><td>bb</td><td>cc</td><td>1</td></tr><tr><td>bb</td><td>cc</td><td>0</td></tr><tr><td>bb</td><td>cc</td><td>0</td></tr><tr><td>bb</td><td>cc</td><td>0</td></tr><tr><td>bb</td><td>dd</td><td>0</td></tr></tbody></table><table><thead><tr><th>x0</th><th>x1</th><th>y</th></tr></thead><tbody><tr><td>0.8</td><td>cc</td><td>1</td></tr><tr><td>0.8</td><td>cc</td><td>1</td></tr><tr><td>0.8</td><td>cc</td><td>1</td></tr><tr><td>0.8</td><td>cc</td><td>1</td></tr><tr><td>0.8</td><td>cc</td><td>0</td></tr><tr><td>0.2</td><td>cc</td><td>1</td></tr><tr><td>0.2</td><td>cc</td><td>0</td></tr><tr><td>0.2</td><td>cc</td><td>0</td></tr><tr><td>0.2</td><td>cc</td><td>0</td></tr><tr><td>0.2</td><td>dd</td><td>0</td></tr></tbody></table><p>​    Target encoding的好处在于它提取了那些可以解释Y值，比如这里得aa拥有了一个Y值的平均值0.8，这会很好的帮助下游机器学习分类算法。</p><p>​    目标编码的问题有一个名称:过拟合。事实上，当平均值的数值很低时，依赖平均值并不总是一个好主意。您必须记住，您正在训练的数据集是一个更大的数据集的样本。这意味着，当您将训练集中发现的任何工件应用到另一个数据集(即测试集)时，可能都不成立。因为有可能训练集内它对应的Y值都是0，但是在测试集中它对应的Y值1比较多。</p><p>​    得出结论，永远不要用基础的target encoding,要用也是用以下的进阶encoding。</p><h2 id="Target-encoding进阶"><a href="#Target-encoding进阶" class="headerlink" title="Target encoding进阶"></a>Target encoding进阶</h2><p>有很多方法可以处理这个问题。</p><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>一种流行的方法是使用交叉验证并计算每个切分数据集中的平均值。这就是H20和许多kaggler所做的。</p><h3 id="additive-smoothing"><a href="#additive-smoothing" class="headerlink" title="additive smoothing"></a>additive smoothing</h3><p>另一种则是 使用<a href="https://www.wikiwand.com/en/Additive_smoothing" target="_blank" rel="noopener">additive smoothing</a>：<br>它使用了全局的平均值来<strong>smooth</strong>较少数据带来过拟合的影响</p><p>数学上它等价于:<br>$$<br>u=\frac{n\times \hat x+m\times w}{n+m}<br>$$</p><p>where</p><ul><li>μ is the mean we’re trying to compute (the one that’s going to replace our categorical values)</li><li>n is the number of values you have</li><li>¯x is your estimated mean</li><li>m is the “weight” you want to assign to the overall mean</li><li>w is the overall mean</li></ul><p>其中m就是用来调节全局的权重，根据他的经验，他发现m取300的时候适用于大多数场合。</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def calc_smooth_mean(df, <span class="keyword">by</span>, <span class="keyword">on</span>, <span class="keyword">m</span>):</span><br><span class="line">    # Compute the <span class="keyword">global</span> <span class="keyword">mean</span></span><br><span class="line">    <span class="keyword">mean</span> = df[<span class="keyword">on</span>].<span class="keyword">mean</span>()</span><br><span class="line"></span><br><span class="line">    # Compute the number of values and the <span class="keyword">mean</span> of each <span class="built_in">group</span></span><br><span class="line">    agg = df.groupby(<span class="keyword">by</span>)[<span class="keyword">on</span>].agg(['<span class="keyword">count</span>', '<span class="keyword">mean</span>'])</span><br><span class="line">    counts = agg['<span class="keyword">count</span>']</span><br><span class="line">    <span class="keyword">means</span> = agg['<span class="keyword">mean</span>']</span><br><span class="line"></span><br><span class="line">    # Compute the <span class="string">"smoothed"</span> <span class="keyword">means</span></span><br><span class="line">    <span class="keyword">smooth</span> = (counts * <span class="keyword">means</span> + <span class="keyword">m</span> * <span class="keyword">mean</span>) / (counts + <span class="keyword">m</span>)</span><br><span class="line"></span><br><span class="line">    # <span class="keyword">Replace</span> each value <span class="keyword">by</span> the according smoothed <span class="keyword">mean</span></span><br><span class="line">    <span class="keyword">return</span> df[<span class="keyword">by</span>].map(<span class="keyword">smooth</span>)</span><br></pre></td></tr></table></figure><h3 id="popular-on-Kaggle"><a href="#popular-on-Kaggle" class="headerlink" title="popular on Kaggle"></a>popular on Kaggle</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​    当你在进行监督学习时，你经常要处理分类变量。也就是说，变量没有一个自然的数值表示。问题是大多数机器学习算法都要求输入数据是数值的。在某个时候，数据科学管道将需要将分类变量转换为数值变量。&lt;/p&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="预处理" scheme="http://kodgv.xyz/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>比赛EDA</title>
    <link href="http://kodgv.xyz/2019/04/08/%E6%AF%94%E8%B5%9BEDA/"/>
    <id>http://kodgv.xyz/2019/04/08/比赛EDA/</id>
    <published>2019-04-08T10:38:48.000Z</published>
    <updated>2019-04-08T16:22:21.341Z</updated>
    
    <content type="html"><![CDATA[<p>比赛常见的EDA总结</p><a id="more"></a><p>[TOC]</p><h2 id="检查缺失值"><a href="#检查缺失值" class="headerlink" title="检查缺失值"></a>检查缺失值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://www.kaggle.com/gpreda/santander-eda-and-prediction</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">missing_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    total = data.isnull().sum()</span><br><span class="line">    percent = (data.isnull().sum()/data.isnull().count()*<span class="number">100</span>)</span><br><span class="line">    tt = pd.concat([total, percent], axis=<span class="number">1</span>, keys=[<span class="string">'Total'</span>, <span class="string">'Percent'</span>])</span><br><span class="line">    types = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> data.columns:</span><br><span class="line">        dtype = str(data[col].dtype)</span><br><span class="line">        types.append(dtype)</span><br><span class="line">    tt[<span class="string">'Types'</span>] = types</span><br><span class="line">    <span class="keyword">return</span>(np.transpose(tt))</span><br></pre></td></tr></table></figure><h2 id="观察分布值"><a href="#观察分布值" class="headerlink" title="观察分布值"></a>观察分布值</h2><h3 id="观察训练集的01分布-可以拓展到任意分布对比图"><a href="#观察训练集的01分布-可以拓展到任意分布对比图" class="headerlink" title="观察训练集的01分布(可以拓展到任意分布对比图)"></a>观察训练集的01分布(可以拓展到任意分布对比图)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://www.kaggle.com/gpreda/santander-eda-and-prediction</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_feature_distribution</span><span class="params">(df1, df2, label1, label2, features)</span>:</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    sns.set_style(<span class="string">'whitegrid'</span>)</span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots(<span class="number">10</span>,<span class="number">10</span>,figsize=(<span class="number">18</span>,<span class="number">22</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        plt.subplot(<span class="number">10</span>,<span class="number">10</span>,i)</span><br><span class="line">        sns.distplot(df1[feature], hist=<span class="literal">False</span>,label=label1)</span><br><span class="line">        sns.distplot(df2[feature], hist=<span class="literal">False</span>,label=label2)</span><br><span class="line">        plt.xlabel(feature, fontsize=<span class="number">9</span>)</span><br><span class="line">        locs, labels = plt.xticks()</span><br><span class="line">        plt.tick_params(axis=<span class="string">'x'</span>, which=<span class="string">'major'</span>, labelsize=<span class="number">6</span>, pad=<span class="number">-6</span>)</span><br><span class="line">        plt.tick_params(axis=<span class="string">'y'</span>, which=<span class="string">'major'</span>, labelsize=<span class="number">6</span>)</span><br><span class="line">    plt.show();</span><br><span class="line">    </span><br><span class="line">t0 = train_df.loc[train_df[<span class="string">'target'</span>] == <span class="number">0</span>]</span><br><span class="line">t1 = train_df.loc[train_df[<span class="string">'target'</span>] == <span class="number">1</span>]</span><br><span class="line">features = train_df.columns.values[<span class="number">2</span>:<span class="number">102</span>]</span><br><span class="line">plot_feature_distribution(t0, t1, <span class="string">'0'</span>, <span class="string">'1'</span>, features)</span><br></pre></td></tr></table></figure><p><img src="https://www.kaggleusercontent.com/kf/12442041/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..mpYQM8lzueJ01ID9kr4OIQ.ku8gk3Hi_tJIUToBxBSfwfdGBwzrSiZOKQTgKK-Re6mOvsG1d-FTEFUvqk12r7Dd-c9ARbOhAu8amY9C2z3_7GSsueWolSsUHTTo0kMSUahGeqHlNjQgEHl3CueKPTwIyA2TcTJbCqHkuyexn9RlAg.xACK-rQek_3z2Ahw9Wv_BQ/__results___files/__results___34_1.png" alt></p><p>结论：We can observe that there is a considerable number of features with significant different distribution for the two target values.<br>For example, <strong>var_0</strong>, <strong>var_1</strong>, <strong>var_2</strong>, <strong>var_5</strong>, <strong>var_9</strong>, <strong>var_13</strong>, <strong>var_106</strong>, <strong>var_109</strong>, <strong>var_139</strong> and many others.</p><p>Also some features, like <strong>var_2</strong>, <strong>var_13</strong>, <strong>var_26</strong>, <strong>var_55</strong>, <strong>var_175</strong>, <strong>var_184</strong>, <strong>var_196</strong> shows a distribution that resambles to a bivariate distribution.</p><h3 id="train-test的分布"><a href="#train-test的分布" class="headerlink" title="train_test的分布"></a>train_test的分布</h3><p>同理可以选择train和test的行和列的mean/std/min值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">https://www.kaggle.com/gpreda/santander-eda-<span class="keyword">and</span>-prediction</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Distribution of mean values per column in the train and test set"</span>)</span><br><span class="line">sns.distplot(train_df[features].mean(axis=<span class="number">0</span>),color=<span class="string">"magenta"</span>,kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'train'</span>)</span><br><span class="line">sns.distplot(test_df[features].mean(axis=<span class="number">0</span>),color=<span class="string">"darkblue"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'test'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Distribution of std values per row in the train and test set"</span>)</span><br><span class="line">sns.distplot(train_df[features].std(axis=<span class="number">1</span>),color=<span class="string">"black"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'train'</span>)</span><br><span class="line">sns.distplot(test_df[features].std(axis=<span class="number">1</span>),color=<span class="string">"red"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'test'</span>)</span><br><span class="line">plt.legend();plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Distribution of std values per column in the train and test set"</span>)</span><br><span class="line">sns.distplot(train_df[features].std(axis=<span class="number">0</span>),color=<span class="string">"blue"</span>,kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'train'</span>)</span><br><span class="line">sns.distplot(test_df[features].std(axis=<span class="number">0</span>),color=<span class="string">"green"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'test'</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br><span class="line">t0 = train_df.loc[train_df[<span class="string">'target'</span>] == <span class="number">0</span>]</span><br><span class="line">t1 = train_df.loc[train_df[<span class="string">'target'</span>] == <span class="number">1</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Distribution of mean values per row in the train set"</span>)</span><br><span class="line">sns.distplot(t0[features].mean(axis=<span class="number">1</span>),color=<span class="string">"red"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'target = 0'</span>)</span><br><span class="line">sns.distplot(t1[features].mean(axis=<span class="number">1</span>),color=<span class="string">"blue"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'target = 1'</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Distribution of mean values per column in the train set"</span>)</span><br><span class="line">sns.distplot(t0[features].mean(axis=<span class="number">0</span>),color=<span class="string">"green"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'target = 0'</span>)</span><br><span class="line">sns.distplot(t1[features].mean(axis=<span class="number">0</span>),color=<span class="string">"darkblue"</span>, kde=<span class="literal">True</span>,bins=<span class="number">120</span>, label=<span class="string">'target = 1'</span>)</span><br><span class="line">plt.legend(); plt.show()</span><br></pre></td></tr></table></figure><h2 id="检查duplicate-values"><a href="#检查duplicate-values" class="headerlink" title="检查duplicate values"></a>检查duplicate values</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">features = train_df.columns.values[<span class="number">2</span>:<span class="number">202</span>]</span><br><span class="line">unique_max_train = []</span><br><span class="line">unique_max_test = []</span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">    values = train_df[feature].value_counts()</span><br><span class="line">    unique_max_train.append([feature, values.max(), values.idxmax()])</span><br><span class="line">    values = test_df[feature].value_counts()</span><br><span class="line">    unique_max_test.append([feature, values.max(), values.idxmax()])</span><br></pre></td></tr></table></figure><h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><p><a href="https://zhuanlan.zhihu.com/p/28909807" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/28909807</a></p><p>主成分分析是统计方法里的一种降维方法，它的主要思想是将原有 <img src="https://www.zhihu.com/equation?tex=n" alt="n"> 个特征通过正交变换将一组可能存在相关性的特征缩减到 <img src="https://www.zhihu.com/equation?tex=k" alt="k"> 特征( <img src="https://www.zhihu.com/equation?tex=k%5Cleq+n" alt="k\leq n"> )。举例来说，在网站用户行为数据收集过程中，会话数(Visits)，浏览页数(PV)，网站总停留时间(Time Spend Total)，访问人数(Unique Visitor)，以上这几个指标，无论是从以往的数据统计还是业务经验来看，都存在一定正相关关系，如果将这些特征喂给模型，很容易造成过拟合。</p><p>通过转化，从而剔除噪声，而且可以看到转化后的值然后把一些无关的列再剔除</p><h2 id="PCA-使用要点"><a href="#PCA-使用要点" class="headerlink" title="PCA 使用要点"></a><strong>PCA 使用要点</strong></h2><ol><li><p>使用主成分分析，往往会丢失掉“少部分信息”（注意：这“少部分信息”仅仅指方差较小的数据，并非信息含量真的少的数据！）</p></li><li><p>因为1的特性，所以在机器学些中，不推荐使用 PCA 去优化特征达到避免过拟合的目的。</p></li><li><p>既然PCA不能避免过拟合，那为何还要使用，根据周志华老师的西瓜书中的描述：</p></li><li><ol><li>在舍弃特征值较小的特征之后，能够使样本采集密度增</li><li>当数据受到噪声影响时，最小的特征值对对应的特征向量往往与噪声有关将他们舍弃能够在一定程度上起到去噪效果</li></ol></li><li><p>在维度过多的情况下，变换后的坐标系代表的意义不明，不易于解释。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://www.kaggle.com/roydatascience/eda-pca-lgbm-santander-transactions/notebook</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> KernelPCA</span><br><span class="line"></span><br><span class="line">lin_pca = KernelPCA(n_components = <span class="number">2</span>, kernel=<span class="string">"linear"</span>, fit_inverse_transform=<span class="literal">True</span>)</span><br><span class="line">rbf_pca = KernelPCA(n_components = <span class="number">2</span>, kernel=<span class="string">"rbf"</span>, gamma=<span class="number">0.0433</span>, fit_inverse_transform=<span class="literal">True</span>)</span><br><span class="line">sig_pca = KernelPCA(n_components = <span class="number">2</span>, kernel=<span class="string">"sigmoid"</span>, gamma=<span class="number">0.001</span>, coef0=<span class="number">1</span>, fit_inverse_transform=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">11</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> subplot, pca, title <span class="keyword">in</span> ((<span class="number">131</span>, lin_pca, <span class="string">"Linear kernel"</span>), (<span class="number">132</span>, rbf_pca, <span class="string">"RBF kernel, $\gamma=0.04$"</span>), </span><br><span class="line">                            (<span class="number">133</span>, sig_pca, <span class="string">"Sigmoid kernel, $\gamma=10^&#123;-3&#125;, r=1$"</span>)):</span><br><span class="line">       </span><br><span class="line">    PCA_train_x = PCA(<span class="number">2</span>).fit_transform(train_scaled)</span><br><span class="line">    plt.subplot(subplot)</span><br><span class="line">    plt.title(title, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.scatter(PCA_train_x[:, <span class="number">0</span>], PCA_train_x[:, <span class="number">1</span>], c=target, cmap=<span class="string">"nipy_spectral_r"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"$z_1$"</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">if</span> subplot == <span class="number">131</span>:</span><br><span class="line">        plt.ylabel(<span class="string">"$z_2$"</span>, fontsize=<span class="number">18</span>, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;比赛常见的EDA总结&lt;/p&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="python" scheme="http://kodgv.xyz/tags/python/"/>
    
      <category term="预处理" scheme="http://kodgv.xyz/tags/%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>numpy</title>
    <link href="http://kodgv.xyz/2019/04/08/numpy/"/>
    <id>http://kodgv.xyz/2019/04/08/numpy/</id>
    <published>2019-04-08T08:31:21.000Z</published>
    <updated>2019-04-08T10:18:18.966Z</updated>
    
    <content type="html"><![CDATA[<p>numpy 操作小技巧<br><a id="more"></a></p><h2 id="增加"><a href="#增加" class="headerlink" title="增加"></a>增加</h2><p>concat/vstack/hstack</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:<span class="regexp">//</span>blog.csdn.net<span class="regexp">/xiaodongxiexie/</span>article<span class="regexp">/details/</span><span class="number">71774466</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;numpy 操作小技巧&lt;br&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="Numpy" scheme="http://kodgv.xyz/tags/Numpy/"/>
    
      <category term="机器学习" scheme="http://kodgv.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://kodgv.xyz/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python代码</title>
    <link href="http://kodgv.xyz/2019/04/08/python%E4%BB%A3%E7%A0%81/"/>
    <id>http://kodgv.xyz/2019/04/08/python代码/</id>
    <published>2019-04-08T08:12:31.000Z</published>
    <updated>2019-04-08T12:17:39.698Z</updated>
    
    <content type="html"><![CDATA[<p>python 代码小技巧</p><a id="more"></a><p>[TOC]</p><h2 id="通用"><a href="#通用" class="headerlink" title="通用"></a>通用</h2><h3 id="测试时间"><a href="#测试时间" class="headerlink" title="测试时间"></a>测试时间</h3><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">关注walltime</span><br><span class="line"><span class="meta">%</span><span class="meta">%</span>time</span><br></pre></td></tr></table></figure><h2 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h2><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index, item <span class="keyword">in</span> enumerate(list1):</span><br><span class="line">    <span class="keyword">print</span> index, item</span><br></pre></td></tr></table></figure><h3 id="通过字典保存了所有中间过程，不仅命名容易，而且便于后续操作"><a href="#通过字典保存了所有中间过程，不仅命名容易，而且便于后续操作" class="headerlink" title="通过字典保存了所有中间过程，不仅命名容易，而且便于后续操作"></a>通过字典保存了所有中间过程，不仅命名容易，而且便于后续操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;d_name:get_dvalue(d_name) <span class="keyword">for</span> d_name <span class="keyword">in</span> d_list&#125;</span><br><span class="line">best_dvalue_dname=min(d.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这样会比单纯用readlines()快</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> index, line <span class="keyword">in</span> enumerate(open(filepath,<span class="string">'r'</span>))： </span><br><span class="line">    count += <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections import defaultdict 通过这个声明dict&#123;里面的格式&#125;</span><br><span class="line">如 defaultdict(<span class="built_in">list</span>)</span><br></pre></td></tr></table></figure><h3 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. [<span class="selector-tag">i</span> <span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(k) <span class="keyword">if</span> condition]：此时<span class="keyword">if</span>起条件判断作用，满足条件的，将被返回成为最终生成的列表的一员。</span><br><span class="line"><span class="number">2</span>. [<span class="selector-tag">i</span> <span class="keyword">if</span> condition <span class="keyword">else</span> exp <span class="keyword">for</span> exp]：此时<span class="keyword">if</span>...<span class="keyword">else</span>被用来赋值，满足条件的i以及<span class="keyword">else</span>被用来生成最终的列表</span><br></pre></td></tr></table></figure><h2 id="自带算法库"><a href="#自带算法库" class="headerlink" title="自带算法库"></a>自带算法库</h2><h3 id="数组中查找插入的位置"><a href="#数组中查找插入的位置" class="headerlink" title="数组中查找插入的位置"></a>数组中查找插入的位置</h3><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">返回排序插入的位置，并不是真的插入排序数组中</span><br><span class="line"><span class="symbol">from</span> <span class="keyword">bisect </span><span class="meta">import</span> <span class="keyword">bisect_left, </span><span class="keyword">bisect_right</span></span><br><span class="line"><span class="keyword">end </span>= <span class="keyword">bisect_left(keys, </span><span class="number">0</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;python 代码小技巧&lt;/p&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="机器学习" scheme="http://kodgv.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://kodgv.xyz/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>比赛通用代码</title>
    <link href="http://kodgv.xyz/2019/04/08/%E6%AF%94%E8%B5%9B%E9%80%9A%E7%94%A8%E4%BB%A3%E7%A0%81/"/>
    <id>http://kodgv.xyz/2019/04/08/比赛通用代码/</id>
    <published>2019-04-08T07:58:10.000Z</published>
    <updated>2019-04-08T10:18:51.540Z</updated>
    
    <content type="html"><![CDATA[<p>比赛通用代码</p><a id="more"></a><p>[TOC]</p><h2 id="jupyter-载入代码包"><a href="#jupyter-载入代码包" class="headerlink" title="jupyter 载入代码包"></a>jupyter 载入代码包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_csv</span><br><span class="line"><span class="keyword">import</span> plotly.offline <span class="keyword">as</span> py</span><br><span class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line">pd.options.display.max_columns = <span class="number">100</span></span><br><span class="line">gc.enable()</span><br><span class="line"></span><br><span class="line"><span class="string">'''Displays markdown formatted output like bold, italic bold etc.'''</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Markdown</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bold</span><span class="params">(string)</span>:</span></span><br><span class="line">    display(Markdown(string))</span><br><span class="line"></span><br><span class="line"><span class="string">'''Ignores deprecation warning.'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ignore_warnings</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">import</span> warnings</span><br><span class="line">    warnings.filterwarnings(<span class="string">'ignore'</span>, category = DeprecationWarning)  </span><br><span class="line">bold(<span class="string">'**Merged data:**'</span>)</span><br><span class="line">display(merged.head())</span><br></pre></td></tr></table></figure><h2 id="自动压缩变量空间"><a href="#自动压缩变量空间" class="headerlink" title="自动压缩变量空间"></a>自动压缩变量空间</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_mem_usage</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="string">""" iterate through all the columns of a dataframe and modify the data type</span></span><br><span class="line"><span class="string">        to reduce memory usage.        </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#start_mem = df.memory_usage().sum() / 1024**2</span></span><br><span class="line">    <span class="comment">#print('Memory usage of dataframe is &#123;:.2f&#125; MB'.format(start_mem))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        col_type = df[col].dtype</span><br><span class="line">        <span class="keyword">if</span> col_type != object:</span><br><span class="line">            c_min = df[col].min()</span><br><span class="line">            c_max = df[col].max()</span><br><span class="line">            <span class="keyword">if</span> str(col_type)[:<span class="number">3</span>] == <span class="string">'int'</span>:</span><br><span class="line">                <span class="keyword">if</span> c_min &gt; np.iinfo(np.int8).min <span class="keyword">and</span> c_max &lt; np.iinfo(np.int8).max:</span><br><span class="line">                    df[col] = df[col].astype(np.int8)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int16).min <span class="keyword">and</span> c_max &lt; np.iinfo(np.int16).max:</span><br><span class="line">                    df[col] = df[col].astype(np.int16)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int32).min <span class="keyword">and</span> c_max &lt; np.iinfo(np.int32).max:</span><br><span class="line">                    df[col] = df[col].astype(np.int32)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.iinfo(np.int64).min <span class="keyword">and</span> c_max &lt; np.iinfo(np.int64).max:</span><br><span class="line">                    df[col] = df[col].astype(np.int64)  </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> c_min &gt; np.finfo(np.float16).min <span class="keyword">and</span> c_max &lt; np.finfo(np.float16).max:</span><br><span class="line">                    df[col] = df[col].astype(np.float16)</span><br><span class="line">                <span class="keyword">elif</span> c_min &gt; np.finfo(np.float32).min <span class="keyword">and</span> c_max &lt; np.finfo(np.float32).max:</span><br><span class="line">                    df[col] = df[col].astype(np.float32)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df[col] = df[col].astype(np.float64)</span><br><span class="line">                </span><br><span class="line">    <span class="comment">#end_mem = df.memory_usage().sum() / 1024**2</span></span><br><span class="line">    <span class="comment">#print('Memory usage after optimization is: &#123;:.2f&#125; MB'.format(end_mem))</span></span><br><span class="line">    <span class="comment">#print('Decreased by &#123;:.1f&#125;%'.format(100 * (start_mem - end_mem) / start_mem))</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reload</span><span class="params">()</span>:</span></span><br><span class="line">    gc.collect()</span><br><span class="line">    df = pd.read_csv(<span class="string">'../input/train_V2.csv'</span>)</span><br><span class="line">    invalid_match_ids = df[df[<span class="string">'winPlacePerc'</span>].isna()][<span class="string">'matchId'</span>].values</span><br><span class="line">    df = df[-df[<span class="string">'matchId'</span>].isin(invalid_match_ids)]</span><br><span class="line">    df=reduce_mem_usage(df)</span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;比赛通用代码&lt;/p&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="机器学习" scheme="http://kodgv.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://kodgv.xyz/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>pandas</title>
    <link href="http://kodgv.xyz/2019/04/08/pandas/"/>
    <id>http://kodgv.xyz/2019/04/08/pandas/</id>
    <published>2019-04-08T07:43:28.000Z</published>
    <updated>2019-04-08T10:18:18.062Z</updated>
    
    <content type="html"><![CDATA[<p>pandas 操作小技巧</p><a id="more"></a><h2 id="通用操作"><a href="#通用操作" class="headerlink" title="通用操作"></a>通用操作</h2><h3 id="pandas操作出现进度条："><a href="#pandas操作出现进度条：" class="headerlink" title="pandas操作出现进度条："></a>pandas操作出现进度条：</h3><ul><li>用作迭代器</li><li>用于Pandas的操作<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line">tqdm.pandas()</span><br><span class="line">sentences = train[<span class="string">"question_text"</span>].progress_apply(<span class="keyword">lambda</span> x: x.split()).values</span><br><span class="line"><span class="keyword">for</span> sentence <span class="keyword">in</span> tqdm(sentences, disable = (<span class="keyword">not</span> verbose)):</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://img-blog.csdnimg.cn/20190117214323585.png" alt="在这里插入图片描述"></p><h2 id="增加"><a href="#增加" class="headerlink" title="增加"></a>增加</h2><h3 id="merge-concat-join"><a href="#merge-concat-join" class="headerlink" title="merge/concat/join"></a>merge/concat/join</h3><p><a href="https://www.e-learn.cn/content/qita/814185" target="_blank" rel="noopener">https://www.e-learn.cn/content/qita/814185</a></p><h2 id="改变"><a href="#改变" class="headerlink" title="改变"></a>改变</h2><h3 id="直接replace"><a href="#直接replace" class="headerlink" title="直接replace"></a>直接replace</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.'''</span></span><br><span class="line">merged.Title.replace(to_replace = [<span class="string">'Dona'</span>, <span class="string">'Jonkheer'</span>, <span class="string">'Countess'</span>, <span class="string">'Sir'</span>, <span class="string">'Lady'</span>, <span class="string">'Don'</span>], value = <span class="string">'Aristocrat'</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>map映射</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#map映射 它就会自动把类别型转为连续型</span></span><br><span class="line"><span class="comment">#如果要Inverse就直接key-value逆转</span></span><br><span class="line">size_mapping=&#123;<span class="string">'XL'</span>:<span class="number">3</span>,<span class="string">'L'</span>:<span class="number">2</span>,<span class="string">'M'</span>:<span class="number">1</span>&#125;</span><br><span class="line">df[<span class="string">'size'</span>]=df[<span class="string">'size'</span>].map(size_mapping)</span><br></pre></td></tr></table></figure><h3 id="单列分箱"><a href="#单列分箱" class="headerlink" title="单列分箱"></a>单列分箱</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''Create bin categories for Age.'''</span></span><br><span class="line">label_names = [<span class="string">'infant'</span>,<span class="string">'child'</span>,<span class="string">'teenager'</span>,<span class="string">'young_adult'</span>,<span class="string">'adult'</span>,<span class="string">'aged'</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''Create range for each bin categories of Age.'''</span></span><br><span class="line">cut_points = [<span class="number">0</span>,<span class="number">5</span>,<span class="number">12</span>,<span class="number">18</span>,<span class="number">35</span>,<span class="number">60</span>,<span class="number">81</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">'''Create and view categorized Age with original Age.'''</span></span><br><span class="line">merged[<span class="string">'Age_binned'</span>] = pd.cut(merged.Age, cut_points, labels = label_names)</span><br><span class="line">display(merged[[<span class="string">'Age'</span>, <span class="string">'Age_binned'</span>]].head(<span class="number">2</span>)</span><br><span class="line">​</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 删除</span><br><span class="line"></span><br><span class="line">### 去重</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',</span><br><span class="line"> 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;pandas 操作小技巧&lt;/p&gt;
    
    </summary>
    
      <category term="数据竞赛" scheme="http://kodgv.xyz/categories/%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="机器学习" scheme="http://kodgv.xyz/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="python" scheme="http://kodgv.xyz/tags/python/"/>
    
      <category term="pandas" scheme="http://kodgv.xyz/tags/pandas/"/>
    
  </entry>
  
</feed>
